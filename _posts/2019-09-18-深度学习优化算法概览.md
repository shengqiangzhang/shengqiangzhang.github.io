---
layout: article
title: 深度学习优化算法概览
tags:
    - Deep Learning
---

深度学习优化算法经历了 SGD -> SGDM -> NAG ->AdaGrad -> AdaDelta -> Adam -> Nadam 这样的发展历程。

知乎上的文章写得挺好的了，所以不整理笔记了，直接贴上对应的链接。

[1\. 从 SGD 到 Adam —— 深度学习优化算法概览(一) - 骆梁宸的文章 - 知乎](https://zhuanlan.zhihu.com/p/32626442)  
[2\. 一个框架看懂优化算法之异同 SGD/AdaGrad/Adam - Juliuszh的文章 - 知乎](https://zhuanlan.zhihu.com/p/32230623)  
[3\. Adam那么棒，为什么还对SGD念念不忘 (2)—— Adam的两宗罪 - Juliuszh的文章 - 知乎](https://zhuanlan.zhihu.com/p/32262540)